{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST (Hand-written Digit) Classification\n",
    "\n",
    "First, import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.misc\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "from tensorflow.contrib.tensorboard.plugins import projector\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the MNIST data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"MNIST_data/\", one_hot=True)\n",
    "mnist_dim = mnist.train.images.shape[1]\n",
    "mnist_size = np.int(np.sqrt(mnist_dim))\n",
    "mnist_classes = mnist.train.labels.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Log Directory\n",
    "TensorFlow need a log directory to write summaries and save checkpoints. We can log the result of different runs into different subdirectory (e.g. `./log/run0001`), and we can view the results from all runs by launching TensorBoard with `--logdir=PARENT_LOG_DIR` (e.g. `--logdir=./log`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def logdir(mkdir=False):\n",
    "    \"\"\"Generates new log directory path.\n",
    "\n",
    "    The log directory is of the format ./log/run####\n",
    "\n",
    "    Args:\n",
    "        mkdir (bool): Creates the directory if mkdir is true. Returns\n",
    "            the path without creating the directory otherwise.\n",
    "\n",
    "    Returns:\n",
    "        string: Log directory path. Returns None if failed to generate\n",
    "            a new log path.\n",
    "\n",
    "    \"\"\"\n",
    "    MAX_RUNS = 10000\n",
    "    base = os.path.abspath('./log')\n",
    "    for i in range(MAX_RUNS):\n",
    "        result = os.path.join(base, 'run{:04d}'.format(i))\n",
    "        if not os.path.exists(result):\n",
    "            if mkdir:\n",
    "                os.makedirs(result)\n",
    "            return result\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will have two summary writers: one for the train dataset and one for the validation dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LOGDIR = logdir(mkdir=True)\n",
    "train_writer = tf.summary.FileWriter(os.path.join(LOGDIR, 'train'))\n",
    "test_writer = tf.summary.FileWriter(os.path.join(LOGDIR, 'test'))\n",
    "print('log dir is: {0}'.format(LOGDIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Layers\n",
    "We will build a feed-forward neural network for MNIST classification. Our network architecture will be composed convolution-max-pooling layer, fully-connected layer, and readout layer (predicting the label). It will be more organized to define a layer function for creating a layer as opposed to putting all the graph construction code in one place. Below, we are defining:\n",
    "- readout layer\n",
    "- fully-connected (fc) layer\n",
    "- convolution-max-pooling (cp) layer\n",
    "\n",
    "Note that in each function, we use the `variable_scope` so the computation nodes and the variables in the graph will be organized by the layer. Also, we create a histogram summary of the layer weights, biases and activations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_readout_layer(input_tensor, name=None):\n",
    "    \"\"\"Constructs a readout layer.\n",
    "\n",
    "    A readout layer takes in a tensor of shape [batch_size, input_dim], and produce a softmax\n",
    "    output of shape [batch_size, num_classes] according to\n",
    "\n",
    "            output = softmax(W * input + b)\n",
    "\n",
    "    Args:\n",
    "        input_tensor (tensor): 2D tensor of shape [batch_size, input_dim].\n",
    "        name (string): Name for the layer variable scope. Default to 'readout_layer'.\n",
    "\n",
    "    Returns:\n",
    "        (logits, softmax): both are 2D tensor of shape [batch_size, num_classes]\n",
    "\n",
    "    \"\"\"\n",
    "    input_dim = input_tensor.shape[1]\n",
    "    with tf.variable_scope(name, 'readout_layer', [input_tensor]):\n",
    "        W = tf.get_variable('W', shape=[input_dim, mnist_classes], initializer=tf.truncated_normal_initializer())\n",
    "        b = tf.get_variable('b', shape=[1, mnist_classes], initializer=tf.zeros_initializer())\n",
    "        logits = tf.add(tf.matmul(input_tensor, W), b, name='logits')\n",
    "        tf.summary.histogram('W', W)\n",
    "        tf.summary.histogram('b', b)\n",
    "        tf.summary.histogram('logits', logits)\n",
    "        return logits, tf.nn.softmax(logits, name='softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_fc_layer(input_tensor, output_dim, activation_fn=tf.nn.relu, name=None):\n",
    "    \"\"\"Constructs a fully-connected layer.\n",
    "\n",
    "    A fully-connected layer takes in a tensor of shape [batch_size, input_dim], and produce an\n",
    "    output of shape [batch_size, output_dim] according to\n",
    "    \n",
    "            output = activation_fn(W * input + b)\n",
    "\n",
    "    Args:\n",
    "        input_tensor (tensor): 2D tensor of shape [batch_size, input_dim].\n",
    "        output_dim (int): An integer specifying the output dimension.\n",
    "        activation_fn (element-wise function): A TensorFlow element-wise function for the\n",
    "            layer activation function. Default to ReLU.\n",
    "        name (string): Name for the layer variable scope. Default to 'fc_layer'.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: of shape [batch_size, output_dim]\n",
    "\n",
    "    \"\"\"\n",
    "    input_dim = input_tensor.shape[1]\n",
    "    with tf.variable_scope(name, 'fc_layer', [input_tensor]):\n",
    "        W = tf.get_variable('W', shape=[input_dim, output_dim], initializer=tf.truncated_normal_initializer())\n",
    "        b = tf.get_variable('b', shape=[1, output_dim], initializer=tf.zeros_initializer())\n",
    "        output_tensor = activation_fn(tf.matmul(input_tensor, W) + b, name='activations')\n",
    "        tf.summary.histogram('W', W)\n",
    "        tf.summary.histogram('b', b)\n",
    "        tf.summary.histogram('activations', output_tensor)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_cp_layer(input_tensor, out_channels, pool_size, filter_size=3, activation_fn=tf.nn.relu, name=None):\n",
    "    \"\"\"Constructs a convolution-max-pooling layer.\n",
    "\n",
    "    A layer that convolves an input with filters and then performing max-pooling. The input shape should\n",
    "    be [batch_size, height, width, channels]. The output tensor shape will be [batch_size, out_height,\n",
    "    out_width, out_channels] where out_height and out_width depends on the pool_size and filter_size\n",
    "\n",
    "    Args:\n",
    "        input_tensor (tensor): 2D tensor of shape [batch_size, height, width, channels].\n",
    "        output_channels (int): An integer specifying the number of output channels.\n",
    "        pool_size (int): The max pooling window is pool_size x pool_size.\n",
    "        filter_size (int): The filter shape is filter_size x filter_size.\n",
    "        activation_fn (element-wise function): A TensorFlow element-wise function for the\n",
    "            layer activation function. Default to ReLU.\n",
    "        name (string): Name for the layer variable scope. Default to 'cp_layer'.\n",
    "\n",
    "    Returns:\n",
    "        Tensor: of shape [batch_size, out_height, out_width, out_channels]\n",
    "\n",
    "    \"\"\"\n",
    "    in_channels = input_tensor.shape[3]\n",
    "    with tf.variable_scope(name, 'cp_layer', [input_tensor]):\n",
    "        W = tf.get_variable('W', shape=[filter_size, filter_size, in_channels, out_channels],\n",
    "                            initializer=tf.truncated_normal_initializer())\n",
    "        b = tf.get_variable('b', shape=[1, 1, 1, out_channels], initializer=tf.zeros_initializer())\n",
    "        strides = [1, 1, 1, 1]\n",
    "        conv_output = activation_fn(tf.nn.conv2d(input_tensor, W, strides, padding='VALID') + b)\n",
    "        output_tensor = tf.nn.max_pool(conv_output,\n",
    "                                       [1, pool_size, pool_size, 1],\n",
    "                                       [1, pool_size, pool_size, 1],\n",
    "                                       padding='VALID')\n",
    "        tf.summary.histogram('W', W)\n",
    "        tf.summary.histogram('b', b)\n",
    "        tf.summary.histogram('activations', output_tensor)\n",
    "        return output_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining Metrics and Training\n",
    "In the TensorFlow graph, we also need to define metrics and a training op.\n",
    "\n",
    "Metrics are used to measure how good our model is. Here we define two metrics: __cross-entropy loss__ and __accuracy__. Cross-entropy loss measures the difference in distribution between the classification predicted by the model and the ground-truth labels. This loss is optimized during training. Accuracy measures the ratio of correct predictions to the number of samples.\n",
    "\n",
    "The training op is created from an __Adam__ optimizer. This optimizer usually gives a fast convergence. We can experiment with different optimizers and see which one gives the best result.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_metrics(onehot_labels, logits, name=None):\n",
    "    \"\"\"Creates cross-entropy loss and accuracy metrics.\n",
    "\n",
    "    Args:\n",
    "        onehot_labels (tensor): 2D tensor of shape [batch_size, num_classes]. Ground-truth labels in\n",
    "            one_hot format.\n",
    "        logits (tensor): 2D tensor of shape [batch_size, num_classes]. Logits of the softmax prediction.\n",
    "        name (string): Name for the scope. Default to 'metrics'.\n",
    "\n",
    "    Returns:\n",
    "        Dictionary: containing cross-entropy loss (with key 'loss') and accuracy (with key 'accuracy').\n",
    "            Both metrics are scaler tensors.\n",
    "\n",
    "    \"\"\"\n",
    "    with tf.name_scope(name, 'metrics', [onehot_labels, logits]):\n",
    "        metrics = {}\n",
    "        \n",
    "        # Cross-entropy loss.\n",
    "        with tf.name_scope('loss', values=[onehot_labels, logits]):\n",
    "            metrics['loss'] = tf.losses.softmax_cross_entropy(onehot_labels, logits, label_smoothing=0.01)\n",
    "            tf.summary.scalar('loss', metrics['loss'])\n",
    "        \n",
    "        # Accuracy.\n",
    "        with tf.name_scope('accuracy', values=[onehot_labels, logits]):\n",
    "            labels = tf.argmax(onehot_labels, axis=-1, name='labels')\n",
    "            predictions = tf.argmax(logits, axis=-1, name='predictions')\n",
    "            metrics['accuracy'] = tf.reduce_mean(tf.cast(tf.equal(labels, predictions), tf.float32))\n",
    "            tf.summary.scalar('accuracy', metrics['accuracy'])\n",
    "        \n",
    "        return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_training(loss, global_step, name=None):\n",
    "    \"\"\"Returns a training op from Adam optimizer.\"\"\"\n",
    "    with tf.name_scope(name, 'training', [loss, global_step]):\n",
    "        optimizer = tf.train.AdamOptimizer()\n",
    "        return optimizer.minimize(loss, global_step)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Embedding Visualization\n",
    "It's difficult to understand how exactly a neural network can achieve its objective (in this case classifying MNIST digits). One way to help us understand a neural network is to visualize its hidden states. Here we will visualize its hidden states, which have high dimensionality, by projecting them onto a lower dimension space (2D or 3D). A TensorBoard plugin called __Projector__ allows us to project a set of vectors (in this case hidden states) onto their PCA space, or alternatively embeds them in a low dimensional space using tSNE technique.\n",
    "\n",
    "We will think of how our neural network as follows. The layers up until the last hidden layer transform the MNIST images into a space where different digits are easily seperable. The readout layer works in this space, so it can accurately label the digits\n",
    "\n",
    "The two functions defined below are for embedding visualization. The first function, `create_projector_meta` creates metadata for the embeddings (the corresponding images and labels). The second function `add_projector` creates a config for embedding visualization for the given variable containing the embeddings.\n",
    "\n",
    "Later in the graph construction code and the model training code, we will compute the embeddings (last hidden states) of the validation dataset and visualize them. Also, we will compare the seperability of the embeddings to one of the raw MNIST images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_projector_meta(directory, mnist):\n",
    "    labels = np.argmax(mnist.labels, axis=1)\n",
    "    count = labels.size\n",
    "    \n",
    "    with open(os.path.join(directory, 'metadata.tsv'), 'w') as f:\n",
    "        for label in labels:\n",
    "            f.write(str(label) + '\\n')\n",
    "\n",
    "    sprite_size = np.int(np.ceil(np.sqrt(count)))\n",
    "    sprite_im = np.empty([sprite_size * mnist_size] * 2, dtype=np.float32)\n",
    "    for i in range(count):\n",
    "        row = (i // sprite_size) * mnist_size\n",
    "        col = (i % sprite_size) * mnist_size\n",
    "        im = 1.0 - np.reshape(mnist.images[i, :], [mnist_size, mnist_size])\n",
    "        sprite_im[row:row+mnist_size, col:col+mnist_size] = im\n",
    "    scipy.misc.toimage(sprite_im, cmin=0.0, cmax=1.0).save(os.path.join(directory, 'sprite.png'))\n",
    "    \n",
    "create_projector_meta(os.path.join(LOGDIR, 'test'), mnist.validation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def add_projector(embedding_vars, writer):\n",
    "    config = projector.ProjectorConfig()\n",
    "    for embedding_var in embedding_vars:\n",
    "        embedding = config.embeddings.add()\n",
    "        embedding.tensor_name = embedding_var.name\n",
    "        embedding.metadata_path = 'metadata.tsv'\n",
    "        embedding.sprite.image_path = 'sprite.png'\n",
    "        embedding.sprite.single_image_dim.extend([mnist_size, mnist_size])\n",
    "    projector.visualize_embeddings(writer, config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building TensorFlow Graph\n",
    "Here the TensorFlow graph is constructed. The network architecture here is 1 convolution-max-pooling layer followed by 1 fully-connected layer, and finally a readout layer. Feel free to experiment with different architecture for the best result.\n",
    "\n",
    "Note that at the end we create a saver object for saving model checkpoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_dim = 784\n",
    "img_size = np.sqrt(img_dim)\n",
    "num_labels = 10\n",
    "mnist.validation.images\n",
    "cp1_outdim = 16\n",
    "cp1_poolsize = 2\n",
    "fc1_dim = 64\n",
    "\n",
    "g = tf.Graph()\n",
    "    \n",
    "with g.as_default():\n",
    "    global_step = tf.Variable(0, trainable=False, name='global_step')\n",
    "    images = tf.placeholder(dtype=tf.float32, shape=[None, mnist_dim], name='images')\n",
    "    labels = tf.placeholder(dtype=tf.float32, shape=[None, mnist_classes], name='labels')\n",
    "    tf.summary.image('MNIST', tf.reshape(images, [-1, mnist_size, mnist_size, 1]))\n",
    "    \n",
    "    # Forward computations\n",
    "    with tf.variable_scope('forward_computation', values=[images, labels]):\n",
    "        cp1_input = tf.reshape(images, [-1, mnist_size, mnist_size, 1], name='cp1_input')\n",
    "        cp1 = add_cp_layer(cp1_input, cp1_outdim, cp1_poolsize, filter_size=5)\n",
    "        cp1_shape = cp1.get_shape()\n",
    "        fc1_input = tf.reshape(cp1, [-1, (cp1_shape[1] * cp1_shape[2] * cp1_shape[3]).value])\n",
    "        fc1 = add_fc_layer(fc1_input, fc1_dim)\n",
    "        logits, output_softmax = add_readout_layer(fc1)\n",
    "        \n",
    "    # Metrics and train_op\n",
    "    metrics = add_metrics(labels, logits)\n",
    "    train_op = add_training(metrics['loss'], global_step)\n",
    "    \n",
    "    # Projector visualization\n",
    "    with tf.variable_scope('projector', values=[fc1], initializer=tf.zeros_initializer):\n",
    "        num_embs = mnist.validation.images.shape[0]\n",
    "        img_embs = tf.get_variable(dtype=tf.float32, name='img_embs',\n",
    "                                   shape=[num_embs, mnist_dim])\n",
    "        fc1_embs = tf.get_variable(dtype=tf.float32, name='fc1_embs',\n",
    "                                   shape=[num_embs, fc1_dim])\n",
    "        emb_op = tf.group(img_embs.assign(images),\n",
    "                          fc1_embs.assign(fc1))\n",
    "        add_projector([img_embs, fc1_embs], test_writer)\n",
    "        \n",
    "    \n",
    "    init_op = tf.global_variables_initializer()\n",
    "    summary = tf.summary.merge_all()\n",
    "    saver = tf.train.Saver()\n",
    "    \n",
    "train_writer.add_graph(g)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "Before the training loop, notice that we restore our model with the lastest checkpoint. Hence, this code block can be interrupted to stop the training, and rerun to continue training.\n",
    "\n",
    "In the training loop, the test summary (metrics on validation dataset) is written every 200 steps. The embedding visualization is updated every 200 steps as well. Notice that the loop breaks with the condition on the global step instead of a local step. This keeps the step counting accurate even if we stop and continue training. This is also beneficial when we train on a cluster with parameter servers and several trainers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "200\n",
      "400\n",
      "600\n",
      "800\n",
      "1000\n",
      "1200\n",
      "1400\n",
      "1600\n",
      "1800\n",
      "2000\n",
      "2200\n",
      "2400\n",
      "2600\n",
      "2800\n",
      "3000\n",
      "3200\n",
      "3400\n",
      "3600\n",
      "3800\n",
      "4000\n",
      "4200\n",
      "4400\n",
      "4600\n",
      "4800\n",
      "5000\n",
      "5200\n",
      "5400\n",
      "5600\n",
      "5800\n",
      "6000\n",
      "6200\n",
      "6400\n",
      "6600\n",
      "6800\n",
      "7000\n",
      "7200\n",
      "7400\n",
      "7600\n",
      "7800\n",
      "8000\n",
      "8200\n",
      "8400\n",
      "8600\n",
      "8800\n",
      "9000\n",
      "9200\n",
      "9400\n",
      "9600\n",
      "9800\n",
      "10000\n",
      "10200\n",
      "10400\n",
      "10600\n",
      "10800\n",
      "11000\n",
      "11200\n",
      "11400\n",
      "11600\n",
      "11800\n",
      "12000\n",
      "12200\n",
      "12400\n",
      "12600\n",
      "12800\n",
      "13000\n",
      "13200\n",
      "13400\n",
      "13600\n",
      "13800\n",
      "14000\n",
      "14200\n",
      "14400\n",
      "14600\n",
      "14800\n",
      "15000\n",
      "15200\n",
      "15400\n",
      "15600\n",
      "15800\n",
      "16000\n",
      "16200\n",
      "16400\n",
      "16600\n",
      "16800\n",
      "17000\n",
      "17200\n",
      "17400\n",
      "17600\n",
      "17800\n",
      "18000\n",
      "18200\n",
      "18400\n",
      "18600\n",
      "18800\n",
      "19000\n",
      "19200\n",
      "19400\n",
      "19600\n",
      "19800\n",
      "20000\n",
      "20200\n",
      "20400\n",
      "20600\n",
      "20800\n",
      "21000\n",
      "21200\n",
      "21400\n",
      "21600\n",
      "21800\n",
      "22000\n",
      "22200\n",
      "22400\n",
      "22600\n",
      "22800\n",
      "23000\n",
      "23200\n",
      "23400\n",
      "23600\n",
      "23800\n",
      "24000\n",
      "24200\n",
      "24400\n",
      "24600\n",
      "24800\n",
      "25000\n",
      "25200\n",
      "25400\n",
      "25600\n",
      "25800\n",
      "26000\n",
      "26200\n",
      "26400\n",
      "26600\n",
      "26800\n",
      "27000\n",
      "27200\n",
      "27400\n",
      "27600\n",
      "27800\n",
      "28000\n",
      "28200\n",
      "28400\n",
      "28600\n",
      "28800\n",
      "29000\n",
      "29200\n",
      "29400\n",
      "29600\n",
      "29800\n",
      "30000\n",
      "30200\n",
      "30400\n",
      "30600\n",
      "30800\n",
      "31000\n",
      "31200\n",
      "31400\n",
      "31600\n",
      "31800\n",
      "32000\n",
      "32200\n",
      "32400\n",
      "32600\n",
      "32800\n",
      "33000\n",
      "33200\n",
      "33400\n",
      "33600\n",
      "33800\n",
      "34000\n",
      "34200\n",
      "34400\n",
      "34600\n",
      "34800\n",
      "35000\n",
      "35200\n",
      "35400\n",
      "35600\n",
      "35800\n",
      "36000\n",
      "36200\n",
      "36400\n",
      "36600\n",
      "36800\n",
      "37000\n",
      "37200\n",
      "37400\n",
      "37600\n",
      "37800\n",
      "38000\n",
      "38200\n",
      "38400\n",
      "38600\n",
      "38800\n",
      "39000\n",
      "39200\n",
      "39400\n",
      "39600\n",
      "39800\n",
      "40000\n",
      "40200\n",
      "40400\n",
      "40600\n",
      "40800\n",
      "41000\n",
      "41200\n",
      "41400\n",
      "41600\n",
      "41800\n",
      "42000\n",
      "42200\n",
      "42400\n",
      "42600\n",
      "42800\n",
      "43000\n",
      "43200\n",
      "43400\n",
      "43600\n",
      "43800\n",
      "44000\n",
      "44200\n",
      "44400\n",
      "44600\n",
      "44800\n",
      "45000\n",
      "45200\n",
      "45400\n",
      "45600\n",
      "45800\n",
      "46000\n",
      "46200\n",
      "46400\n",
      "46600\n",
      "46800\n",
      "47000\n",
      "47200\n",
      "47400\n",
      "47600\n",
      "47800\n",
      "48000\n",
      "48200\n",
      "48400\n",
      "48600\n",
      "48800\n",
      "49000\n",
      "49200\n",
      "49400\n",
      "49600\n",
      "49800\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 50000\n",
    "BATCH_SIZE = 200\n",
    "SAVE_NAME = 'model.ckpt'\n",
    "SAVE_PATH = os.path.join(LOGDIR, SAVE_NAME)\n",
    "sess = tf.Session(graph=g)\n",
    "sess.run(init_op)\n",
    "\n",
    "last_ckpt_path = tf.train.latest_checkpoint(LOGDIR)\n",
    "if last_ckpt_path:\n",
    "    saver.restore(sess, last_ckpt_path)\n",
    "    \n",
    "train_writer.reopen()\n",
    "test_writer.reopen()\n",
    "\n",
    "for _ in range(MAX_STEPS):\n",
    "    i = sess.run(global_step)\n",
    "    if i > MAX_STEPS:\n",
    "        break\n",
    "    train_images, train_labels = mnist.train.next_batch(batch_size=BATCH_SIZE, shuffle=True)\n",
    "    feed_dict = {images:train_images, labels:train_labels}\n",
    "    _, train_summary = sess.run([train_op, summary], feed_dict=feed_dict)\n",
    "    train_writer.add_summary(train_summary, i)\n",
    "    if i % 200 == 0 or i == MAX_STEPS:\n",
    "        print(i)\n",
    "        val_images, val_labels = mnist.validation.images, mnist.validation.labels\n",
    "        feed_dict = {images:val_images, labels:val_labels}\n",
    "        _, test_summary = sess.run([emb_op, summary], feed_dict=feed_dict)\n",
    "        test_writer.add_summary(test_summary, i)\n",
    "        train_writer.flush()\n",
    "        test_writer.flush()\n",
    "        saver.save(sess, SAVE_PATH, global_step=i)\n",
    "\n",
    "train_writer.close()\n",
    "test_writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
